{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f05806",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------\n",
    "# Problem Statement:ADVERTISING SALES PREDICTION\n",
    "#This dataset contains information about advertising spend on different platforms (TV, Radio, Newspaper)\n",
    "#and the resulting sales. The goal is to build a model that can predict sales based on advertising spend.\n",
    "#-----------------------------\n",
    "# Importing Files \n",
    "#-----------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#-----------------------------------------------------------\n",
    "#Importing data\n",
    "data_ads = pd.read_csv('Advertising.csv')\n",
    "#creating a copy of data\n",
    "data = data_ads.copy()\n",
    "#Checking if importing is complete\n",
    "print(data.head())\n",
    "\n",
    "\"\"\"\n",
    "EXPLORATORY DATA ANALYSIS\n",
    "1.Getting to know the data\n",
    "2.Data processing(missing values)\n",
    "3.Cross tables and data visualization\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(data.info())\n",
    "print(\"Data columns with null values:\\n\",data.isnull().sum())\n",
    "#No null values Detected\n",
    "#Summary of Numerical data\n",
    "summary_num = data.describe()\n",
    "print(summary_num)\n",
    "\n",
    "\"\"\"\n",
    "              TV        Radio    Newspaper     Sales\n",
    "count  200.000000  200.000000   200.000000  200.00000\n",
    "mean   147.042500   23.264150    30.554000   14.02250\n",
    "std     85.854236   14.846809    21.778621    5.21745\n",
    "min      0.700000    0.000000     0.300000    1.60000\n",
    "25%     74.375000   11.250000    12.075000   10.37500\n",
    "50%    149.050000   22.900000    25.750000   12.90000\n",
    "75%    218.825000   31.275000    45.100000   17.40000\n",
    "max    296.400000  112.000000   105.400000   27.00000\"\"\"\n",
    "\n",
    "#From the above summary we can see that the data is symmetrically distributed\n",
    "\n",
    "#Summary of categorical values\n",
    "'''summary_cat = data.describe(include='O')\n",
    "print(summary_cat)\n",
    "print(data.columns)'''\n",
    "#frequency of each categories,Find special charecters\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(data['TV'].value_counts())\n",
    "print(data['Radio'].value_counts())\n",
    "print(data['Newspaper'].value_counts())\n",
    "print(data['Sales'].value_counts())\n",
    "#No unique value detected in any of the columns\n",
    "\n",
    "#checking for duplicate values\n",
    "data[data.duplicated()]\n",
    "#Duplicates found\n",
    "data.drop_duplicates()\n",
    "#Dropping duplicates from the dataset\n",
    "#Normalized value counts (percentage)\n",
    "print(data.columns.value_counts(normalize=True))\n",
    "\n",
    "#DATA VISUALIZATION:\n",
    "    \n",
    "#Histogram for numerical columns\n",
    "data.hist(figsize=(10, 5))\n",
    "\"\"\"TV:The data is left-skewed. This shows that most of the advertising spend on TV is relatively low,with a large concentration of values in the lower range. There are very few high TV spends.\n",
    "Radio:This distribution is right-skewed. Most radio advertising spends are under 30,with very few having a high radio spend.\n",
    "Newspaper:Similar to Radio, this is also right-skewed.The majority of newspaper spends are under 50, while very high spends are rare in this dataset.\n",
    "Sales:This is heavily right-skewed. The vast majority of sales values are between 10-20,with a few sales having very high values.\n",
    "\"\"\"\n",
    "\n",
    "#Box plots for outlier detection\n",
    "data.boxplot(figsize=(10,5))\n",
    "\"\"\"TV, Radio, Newspaper, Sales: These features have very compressed box plots, indicating that the majority of their data is clustered within a narrow range. They each show a few high-value outliers.\n",
    "Newspaper:The box itself is relatively small, showing that 50% of the spends have a similar range. However, there are numerous outliers with very high values, indicating a few campaigns with very high newspaper spends.\"\"\"\n",
    "#Box plot for sales\n",
    "data[\"Sales\"].plot(kind=\"box\")\n",
    "#The plot is right skewed.Outliers were detected.\n",
    "#Box plot for TV\n",
    "data[\"TV\"].plot(kind=\"box\")\n",
    "#The plot is also right skewed.A few outliers were detected.\n",
    "\n",
    "#Scatter plot between Sales and TV to find te relation between them\n",
    "data.plot(kind=\"scatter\", x=\"TV\", y=\"Sales\")\n",
    "#A strong positive correlation is observed between the two variables\n",
    "#This may result in a strong factor while preparing the model.\n",
    "\n",
    "print(data.isnull().sum())\n",
    "missing = data[data.isnull().any(axis=1)]#Checking coloumn missing values\n",
    "print(missing)\n",
    "#No missing valuies were found in any columns\n",
    "#Relationship between independent variables\n",
    "# Select only numeric columns\n",
    "numeric_data = data.select_dtypes(include=[np.number])\n",
    "correlation = numeric_data.corr()\n",
    "print(correlation)\n",
    "\"\"\"\n",
    "                   TV     Radio  Newspaper     Sales\n",
    "TV          1.000000  0.054809   0.056648  0.782224\n",
    "Radio       0.054809  1.000000   0.354104  0.576223\n",
    "Newspaper   0.056648  0.354104   1.000000  0.228299\n",
    "Sales       0.782224  0.576223   0.228299  1.000000\"\"\"\n",
    "#The above correlation suggests:\n",
    "    # TV and Sales has a very high correlation\n",
    "    #Radio and Sales has a moderate positive correlation\n",
    "    #Newspaper and Sales has a low positive correlation\n",
    "#consider categorical variables\n",
    "print(data.columns)\n",
    "#preparing cross tables and data visualization\n",
    "#Sales proportion table\n",
    "Sales = pd.crosstab( index = data[\"Sales\"], columns = 'count',normalize=True) \n",
    "print(Sales) \n",
    "#At this point Nothing can be interpreted using the Sales table only, Use other factors with Sales to find important affecting factors\n",
    "\n",
    "#Sales vs TV\n",
    "#Creates a new column in the dataset named \"TV_Category\",Which categorizes TV spend\n",
    "data[\"TV_Category\"] = pd.cut(data[\"TV\"], bins=5, labels=['Very_Low_TV', 'Low_TV', 'Medium_TV', 'High_TV', 'Very_High_TV'])\n",
    "#Using a boxplot\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.boxplot(x='Sales', y='TV_Category', data=data)\n",
    "plt.xlabel(\"Sales\")\n",
    "plt.ylabel(\"TV_Category\")\n",
    "plt.title(\"Distribution of Sales by TV_Category\")\n",
    "plt.show()\n",
    "\"\"\"High-Value TV spends(very high TV) have boxes situated far to the right , which means they have high median sales\n",
    "Wide-Sales range categories like very high TV has a very wide box which means its sales are very spread out.\n",
    "Low-Value TV spends (very low TV) have boxes clustered on the far left,Showing they have a low sales\n",
    "\"\"\"\n",
    "\n",
    "#Using a bar plot\n",
    "TV_sales = data.groupby('TV_Category')[\"Sales\"].mean().sort_values(ascending=False)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=TV_sales.values, y=TV_sales.index)\n",
    "plt.xlabel(\"Average Sales\")\n",
    "plt.ylabel(\"TV_Category\")\n",
    "plt.title(\"Average Sales by TV_Category\")\n",
    "plt.show()\n",
    "\"\"\"As seen in the graph,Very High TV spends has a very high sales value,followed by High TV,Medium TV etc..\n",
    "Categories like Very Low TV and Low TV has low avg sales\n",
    "\"\"\"\n",
    "\n",
    "#Sales vs Radio\n",
    "#Creates a new column in the dataset named \"Radio_Category\",Which categorizes Radio spend\n",
    "data[\"Radio_Category\"] = pd.cut(data[\"Radio\"], bins=5, labels=['Very_Low_Radio', 'Low_Radio', 'Medium_Radio', 'High_Radio', 'Very_High_Radio'])\n",
    "#Using a ScatterPlot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='Radio', y='Sales', data=data)\n",
    "plt.xlabel(\"Radio\")\n",
    "plt.ylabel(\"Sales\")\n",
    "plt.title(\"Sales vs. Radio\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "#A positive correlation is observed with some outliers\n",
    "\n",
    "#Sales vs Newspaper\n",
    "#Creates a new column in the dataset named \"Newspaper_Category\",Which categorizes Newspaper spend\n",
    "data[\"Newspaper_Category\"] = pd.cut(data[\"Newspaper\"], bins=5, labels=['Very_Low_News', 'Low_News', 'Medium_News', 'High_News', 'Very_High_News'])\n",
    "#Using a ScatterPlot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='Newspaper', y='Sales', data=data)\n",
    "plt.xlabel(\"Newspaper\")\n",
    "plt.ylabel(\"Sales\")\n",
    "plt.title(\"Sales vs. Newspaper\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "#A right skewness is observed with a few outliers\n",
    "\n",
    "#Sales vs TV\n",
    "\n",
    "#Using a ScatterPlot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='TV', y='Sales', data=data)\n",
    "plt.xlabel(\"TV\")\n",
    "plt.ylabel(\"Sales\")\n",
    "plt.title(\"Sales vs. TV\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "#We already saw their relation\n",
    "\n",
    "#DATA PREPROCESSING\n",
    "\n",
    "scaler = StandardScaler()\n",
    "#This scales the values to have mean = 0 and standard deviation = 1 to better distribution\n",
    "data[['TV','Radio','Newspaper','Sales']] = scaler.fit_transform(data[['TV','Radio','Newspaper','Sales']])\n",
    "#Handling categorical values\n",
    "data= pd.get_dummies(data, columns=['TV_Category', 'Radio_Category', 'Newspaper_Category'], drop_first=True)\n",
    "#Outlier Handling\n",
    "#TV outliers are being fixed because it contains the maximum outliers and the rest ofthe varibales are replaced with dummy variables\n",
    "Q1 = data['TV'].quantile(0.25)\n",
    "Q3 = data['TV'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "data= data[~((data['TV'] < (Q1 - 1.5 * IQR)) | (data['TV'] > (Q3 + 1.5 * IQR)))]\n",
    "#A total of 200-190 = 10 rows were removed , the method followed to remove outliers was interquantile range\n",
    "print(data.columns)\n",
    "\n",
    "#Creating a ML Model\n",
    "\n",
    "# X contains all the predictive features\n",
    "X = data.drop('Sales', axis=1) \n",
    "# y is the target variable we want to predict\n",
    "y = data['Sales']\n",
    "\n",
    "#Splitting the data so we can train the model and test it on unseen data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Create and Train the Linear Regression Model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Make Predictions on the Test Data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "#R-squared score\n",
    "r2 = metrics.r2_score(y_test, predictions)\n",
    "print(f\"R-squared Score: {r2:.2%}\")\n",
    "#R-squared Score: 90.39%\n",
    "\n",
    "#Mean Absolute Error (MAE)\n",
    "mae = metrics.mean_absolute_error(y_test, predictions)\n",
    "print(f\"Mean Absolute Error (MAE): {mae:,.2f}\")\n",
    "#Mean Absolute Error (MAE): 0.24"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
